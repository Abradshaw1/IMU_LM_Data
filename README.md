# IMU_LM_Data

**Data alignment and unification pipeline for the IMU-LM foundation model.**  
This repository standardizes multiple wearable and activity-recognition datasets into a single unified schema suitable for downstream training of large-scale IMU foundation models.

## ğŸŒ Overview

The goal of this repository is to **consolidate heterogeneous IMU datasets** (e.g., RecoFit, PAMAP2, Opportunity++, Samosa, Wear, UT_Watch) into a **consistent, schema-aligned, and clean format**.  
Each dataset is preprocessed individually before being merged into a unified representation that shares:

- Common sensor channels (e.g., accelerometer, gyroscope, magnetometer)
- Consistent sampling rates and timestamps
- Harmonized activity labels and metadata
- Canonical column names defined in the unification schema

## âš™ï¸ Setup

### 1. Clone the repository

```bash
git clone https://github.com/Abradshaw1/IMU_LM_Data.git
cd IMU_LM_Data
```

### 2. Create a virtual environment

```bash
python3 -m venv .IMUDATA
source .IMUDATA/bin/activate   # Windows: .IMUDATA\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -U pip
pip install -r requirements.txt
```

## ğŸš€ Usage

Step 1 â€” Dataset preprocessing

Run each notebook under `Individual_dataloaders/` to:

- Load raw dataset files
- Apply cleaning, filtering, and normalization
- Export the cleaned dataset to `data/cleaned_premerge/` as a Parquet file

Step 2 â€” Schema unification

In `Unification/merge_pipeline.ipynb`:

- Validate each dataset against `schemas/main_schema.json`
- Apply the global `schemas/activity_mapping.json` to harmonize activity labels
- Merge all datasets into `data/merged_dataset/unified_dataset.parquet`

Step 3 â€” Model integration

The unified dataset can be used directly by IMU foundation-model pipelines (e.g., transformer-based pretraining, contrastive learning, or self-supervised sequence models).

## ğŸ§± Repository Structure

```
IMU_LM_Data/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_data/              # Original downloaded datasets
â”‚   â”œâ”€â”€ cleaned_premerge/      # Cleaned & standardized per-dataset Parquet files
â”‚   â””â”€â”€ merged_dataset/        # Final unified dataset for model training
â”‚
â”œâ”€â”€ Individual_dataloaders/
â”‚   â”œâ”€â”€ Opportunity++/
â”‚   â”œâ”€â”€ PAMAP2/
â”‚   â”œâ”€â”€ RecoFit/
â”‚   â”œâ”€â”€ Samosa/
â”‚   â”œâ”€â”€ UT_Watch/
â”‚   â””â”€â”€ Wear/
â”‚       â”œâ”€â”€ load_and_preprocess.ipynb
â”‚       â””â”€â”€ README.md
â”‚   # Each subfolder: dataset-specific preprocessing, cleaning, mappings
â”‚
â”œâ”€â”€ Unification/
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ main_schema.json         # Canonical column definitions (dtype, semantics)
â”‚   â”‚   â””â”€â”€ activity_mapping.json    # Global label harmonization map
â”‚   â”œâ”€â”€ merge_pipeline.ipynb        # Merges all cleaned datasets â†’ unified Parquet
â”‚   â””â”€â”€ README.md                   # Explains schema design and merge rules
â”‚
â”œâ”€â”€ UTILS/
â”‚   â””â”€â”€ helpers.py                   # Common functions: schema validation, IO, mapping
â”‚
â”œâ”€â”€ requirements.txt                 # Core dependencies (numpy, pandas, pyarrow, etc.)
â””â”€â”€ README.md                        # You are here
```

## ğŸ§  Future Extensions

- Add temporal resampling and device-alignment utilities
- Integrate automatic label cleaning and activity taxonomy matching
- Extend schema to multimodal sensor streams (e.g., PPG, ECG, audio)

## ğŸ“„ License

This project is intended for research and educational use within the IMU-LM project.
