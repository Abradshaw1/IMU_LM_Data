{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d87bee8",
   "metadata": {},
   "source": [
    "## RecoFit Data Preprocessing notebook\n",
    "### Step 0. Setup the paths and env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d8a6ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/aidan/IMU_LM_Data\n",
      "Paths & contracts ready.\n",
      "Schema keys: ['name', 'version', 'primary_index', 'description', 'columns', 'rate_hz', 'axis_frame', 'unit_contract', 'unknown_activity_id', 'expectations']\n",
      "/home/aidan/IMU_LM_Data/data/raw_data/RecoFit/Exercise-Recognition-from-Wearable-Sensors\n",
      "/home/aidan/IMU_LM_Data/data/cleaned_premerge\n",
      "/home/aidan/IMU_LM_Data/data/merged_dataset\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json, sys, os\n",
    "ROOT = Path(\"/home/aidan/IMU_LM_Data\")\n",
    "sys.path.insert(0, str(ROOT)) \n",
    "print(f\"Project root: {ROOT}\")\n",
    "from tqdm import tqdm\n",
    "from UTILS.helpers import resample_df, convert_unit, zscore_normalize, normalize_str, keyize, _keyize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "\n",
    "BASE    = ROOT / \"data\"\n",
    "RAW     = BASE / \"raw_data\" / \"RecoFit\" / \"Exercise-Recognition-from-Wearable-Sensors\"\n",
    "CLEANED = BASE / \"cleaned_premerge\"\n",
    "MERGED  = BASE / \"merged_dataset\"\n",
    "SCHEMA_PATH       = ROOT / \"Unification\" / \"schemas\" / \"continuous_stream_schema.json\"\n",
    "ACTIVITY_MAP_PATH = ROOT / \"Unification\" / \"schemas\" / \"activity_mapping.json\"\n",
    "SCHEMA       = json.loads(SCHEMA_PATH.read_text())\n",
    "ACT_MAP_FULL = json.loads(ACTIVITY_MAP_PATH.read_text())\n",
    "UNKNOWN_ID = int(ACT_MAP_FULL.get(\"unknown_activity_id\", -1))\n",
    "ID2NAME    = {int(x[\"id\"]): x[\"name\"] for x in ACT_MAP_FULL[\"label_set\"]}\n",
    "RAW2ID     = {_keyize(k): int(v) for k, v in ACT_MAP_FULL.get(\"mapping\", {}).items()}\n",
    "\n",
    "print(\"Paths & contracts ready.\")\n",
    "print(f\"Schema keys: {list(SCHEMA.keys())}\")\n",
    "print(RAW)\n",
    "print(CLEANED)\n",
    "print(MERGED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafe0373",
   "metadata": {},
   "source": [
    "### Step 1. Ingest, preporccess and map the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc5d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "subjects: 100%|██████████| 94/94 [00:07<00:00, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RAW SUMMARY ===\n",
      "Shape: 7,751,906 rows × 11 cols\n",
      "Subjects: 94 | Sessions: 73 | Raw classes: 73\n",
      "Median Hz across sessions: 50.00\n",
      "Median session duration (s): 46.47\n",
      "\n",
      "Top-15 raw labels:\n",
      "  Device on Table                               1,301,735\n",
      "  Walk                                          608,204\n",
      "  Static stretch                                451,196\n",
      "  Static Stretch (at your own pace)             313,323\n",
      "  Running (treadmill)                           291,569\n",
      "  Dynamic Stretch (at your own pace)            284,271\n",
      "  Elliptical machine                            275,296\n",
      "  Rowing machine                                267,743\n",
      "  Plank                                         139,039\n",
      "  Lunge (alternating both legs, weight optional) 131,904\n",
      "  Butterfly Sit-up                              131,310\n",
      "  Squat (arms in front of body, parallel to ground) 116,623\n",
      "  Non-Exercise                                  116,307\n",
      "  Burpee                                        114,438\n",
      "  Triceps Kickback (knee on bench) (label spans both arms) 108,276\n"
     ]
    }
   ],
   "source": [
    "def preprocess_recofit_imu(imu: np.ndarray, shift_time: bool=False,\n",
    "                           kind: str|None=\"acc\", normalize_imu: bool=False) -> np.ndarray:\n",
    "    imu = imu[np.argsort(imu[:, 0])]\n",
    "    if shift_time:\n",
    "        imu[:, 0] -= imu[0, 0]\n",
    "    if kind is not None:\n",
    "        imu[:, 1:4] = convert_unit(imu[:, 1:4], kind=kind)  # g→m/s², dps→rad/s\n",
    "    if normalize_imu:\n",
    "        imu[:, 1:4] = zscore_normalize(imu[:, 1:4])\n",
    "    return imu\n",
    "\n",
    "def load_recofit_raw(dataset_path: Path) -> pd.DataFrame:\n",
    "    mat = loadmat(dataset_path / \"exercise_data.50.0000_singleonly.mat\")\n",
    "    subject_data = mat[\"subject_data\"]\n",
    "\n",
    "    rows = []\n",
    "    for i in tqdm(range(subject_data.shape[0]), desc=\"subjects\"):\n",
    "        for j in range(subject_data.shape[1]):\n",
    "            cell = subject_data[i, j]\n",
    "            if not isinstance(cell, np.ndarray) or cell.size == 0:\n",
    "                continue\n",
    "            entry = cell[0][0]\n",
    "\n",
    "            activity_index = int(entry[1][0][0])   # native per-dataset ID\n",
    "            raw_label      = str(entry[5][0])      # native label (verbatim)\n",
    "\n",
    "            sensor   = entry[14][0][0]\n",
    "            acc_raw  = sensor[0]\n",
    "            gyro_raw = sensor[1]\n",
    "\n",
    "            acc  = preprocess_recofit_imu(acc_raw,  shift_time=False, kind=\"acc\",  normalize_imu=False)\n",
    "            gyro = preprocess_recofit_imu(gyro_raw, shift_time=False, kind=\"gyro\", normalize_imu=False)\n",
    "            n = min(acc.shape[0], gyro.shape[0])\n",
    "            sid, sess = f\"S{i:02d}\", f\"Trial_{j:02d}\"\n",
    "\n",
    "            rows.extend({\n",
    "                \"subject_id\": sid,\n",
    "                \"session_id\": sess,\n",
    "                \"timestamp_s\": float(acc[k, 0]),\n",
    "                \"acc_x\": float(acc[k, 1]), \"acc_y\": float(acc[k, 2]), \"acc_z\": float(acc[k, 3]),\n",
    "                \"gyro_x\": float(gyro[k, 1]), \"gyro_y\": float(gyro[k, 2]), \"gyro_z\": float(gyro[k, 3]),\n",
    "                \"activity_label_raw\": raw_label,\n",
    "                \"dataset_activity_id\": activity_index,   # NEW (native, stable)\n",
    "            } for k in range(n))\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    print(\"\\n=== RAW SUMMARY ===\")\n",
    "    print(f\"Shape: {df.shape[0]:,} rows × {df.shape[1]} cols\")  # dimensions\n",
    "\n",
    "    if len(df):\n",
    "        # Avoid FutureWarning by selecting the series before apply\n",
    "        def est_hz(ts: pd.Series):\n",
    "            arr = ts.to_numpy()\n",
    "            if arr.size < 3: return np.nan\n",
    "            dt = np.diff(arr)\n",
    "            dt = dt[(dt > 0) & np.isfinite(dt)]\n",
    "            return float(np.median(1.0 / dt)) if dt.size else np.nan\n",
    "\n",
    "        def sess_dur(ts: pd.Series):\n",
    "            arr = ts.to_numpy()\n",
    "            return float(arr[-1] - arr[0]) if arr.size > 1 else 0.0\n",
    "\n",
    "        hz = df.groupby([\"subject_id\", \"session_id\"])[\"timestamp_s\"].apply(est_hz)\n",
    "        dur = df.groupby([\"subject_id\", \"session_id\"])[\"timestamp_s\"].apply(sess_dur)\n",
    "\n",
    "        n_subjects = df[\"subject_id\"].nunique()\n",
    "        n_sessions = df[\"session_id\"].nunique()\n",
    "\n",
    "        # total *raw* classes (case-insensitive)\n",
    "        n_classes = df[\"activity_label_raw\"].str.lower().nunique()\n",
    "\n",
    "        print(f\"Subjects: {n_subjects} | Sessions: {n_sessions} | Raw classes: {n_classes}\")\n",
    "        print(f\"Median Hz across sessions: {np.nanmedian(hz.values):.2f}\")\n",
    "        print(f\"Median session duration (s): {np.nanmedian(dur.values):.2f}\")\n",
    "\n",
    "        # top raw labels\n",
    "        top = df[\"activity_label_raw\"].value_counts().head(15)\n",
    "        print(\"\\nTop-15 raw labels:\")\n",
    "        for lbl, cnt in top.items():\n",
    "            print(f\"  {lbl:45s} {cnt:,}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "raw_df = load_recofit_raw(RAW)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aeca27",
   "metadata": {},
   "source": [
    "### Step 2. Map the data and audit the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9e6bb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw label unique: 73 | Unmapped: 1\n",
      "Unmapped (top-10):\n",
      "          raw_label  count\n",
      "arm band adjustment  30194\n"
     ]
    }
   ],
   "source": [
    "# Build an audit table: raw_label -> mapped_id -> mapped_name, with counts\n",
    "# ---- quick audit (no files) ----\n",
    "raw_counts = (\n",
    "    raw_df[\"activity_label_raw\"]\n",
    "      .astype(str).map(_keyize)          # <— normalize BEFORE counting\n",
    "      .value_counts()\n",
    "      .rename_axis(\"raw_label\")\n",
    "      .reset_index(name=\"count\")\n",
    ")\n",
    "raw_counts[\"mapped_id\"] = raw_counts[\"raw_label\"].map(RAW2ID).fillna(UNKNOWN_ID).astype(int)\n",
    "raw_counts[\"mapped_nm\"] = raw_counts[\"mapped_id\"].map(lambda x: ID2NAME.get(int(x), \"other\"))\n",
    "\n",
    "unmapped = raw_counts.loc[raw_counts[\"mapped_id\"] == UNKNOWN_ID]\n",
    "print(f\"Raw label unique: {len(raw_counts)} | Unmapped: {len(unmapped)}\")\n",
    "print(\"Unmapped (top-10):\")\n",
    "print(unmapped.nlargest(10, \"count\")[[\"raw_label\",\"count\"]].to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fcd91c",
   "metadata": {},
   "source": [
    "### Step 3. Build and clean dataset in stream json fromat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4d027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_continuous_stream(df_raw: pd.DataFrame, dataset_name: str=\"recofit\") -> pd.DataFrame:\n",
    "    if df_raw.empty:\n",
    "        return pd.DataFrame(columns=[c[\"name\"] for c in SCHEMA[\"columns\"]])\n",
    "\n",
    "    # ---- GLOBALS: map using activity_mapping.json + normalizer\n",
    "    raw_key = df_raw[\"activity_label_raw\"].astype(str).map(_keyize)\n",
    "    gid = raw_key.map(RAW2ID).fillna(UNKNOWN_ID).astype(\"int16\")\n",
    "    glabel = gid.map(lambda x: ID2NAME.get(int(x), \"other\")).astype(\"string\")\n",
    "\n",
    "    # ---- NATIVE: keep 1:1 with dataset\n",
    "    native_id  = df_raw[\"dataset_activity_id\"].astype(\"Int16\")\n",
    "    native_lbl = df_raw[\"activity_label_raw\"].astype(\"string\")\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"dataset\":        dataset_name,\n",
    "        \"subject_id\":     df_raw[\"subject_id\"].astype(\"string\"),\n",
    "        \"session_id\":     df_raw[\"session_id\"].astype(\"string\"),\n",
    "        \"timestamp_ns\":   (df_raw[\"timestamp_s\"].astype(np.float64) * 1e9).round().astype(\"int64\"),\n",
    "\n",
    "        \"acc_x\": df_raw[\"acc_x\"].astype(\"float32\"),\n",
    "        \"acc_y\": df_raw[\"acc_y\"].astype(\"float32\"),\n",
    "        \"acc_z\": df_raw[\"acc_z\"].astype(\"float32\"),\n",
    "        \"gyro_x\": df_raw[\"gyro_x\"].astype(\"float32\"),\n",
    "        \"gyro_y\": df_raw[\"gyro_y\"].astype(\"float32\"),\n",
    "        \"gyro_z\": df_raw[\"gyro_z\"].astype(\"float32\"),\n",
    "\n",
    "        \"global_activity_id\":    gid,\n",
    "        \"global_activity_label\": glabel,\n",
    "\n",
    "        \"dataset_activity_id\":    native_id,\n",
    "        \"dataset_activity_label\": native_lbl,\n",
    "    })\n",
    "\n",
    "    order = [c[\"name\"] for c in SCHEMA[\"columns\"]]\n",
    "    return out[order]\n",
    "\n",
    "# build the unified frame\n",
    "recofit_df = to_continuous_stream(raw_df, dataset_name=\"recofit\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e6c03",
   "metadata": {},
   "source": [
    "### Step 4. Audit check the unified frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3501c22e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recofit_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUNIFIED rows:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mrecofit_df\u001b[49m))\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSubjects:\u001b[39m\u001b[33m\"\u001b[39m, recofit_df[\u001b[33m\"\u001b[39m\u001b[33msubject_id\u001b[39m\u001b[33m\"\u001b[39m].nunique(), \u001b[33m\"\u001b[39m\u001b[33m| Sessions:\u001b[39m\u001b[33m\"\u001b[39m, recofit_df[\u001b[33m\"\u001b[39m\u001b[33msession_id\u001b[39m\u001b[33m\"\u001b[39m].nunique())\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# monotonic per (subject,session)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'recofit_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"UNIFIED rows:\", len(recofit_df))\n",
    "print(\"Subjects:\", recofit_df[\"subject_id\"].nunique(), \"| Sessions:\", recofit_df[\"session_id\"].nunique())\n",
    "\n",
    "# monotonic per (subject,session)\n",
    "viol = 0\n",
    "for (_sid, _sess), g in recofit_df.groupby([\"subject_id\",\"session_id\"], sort=False):\n",
    "    ts = g[\"timestamp_ns\"].to_numpy()\n",
    "    if ts.size and not np.all(np.diff(ts) >= 0):\n",
    "        viol += 1\n",
    "print(\"Monotonic violations (groups):\", viol)\n",
    "\n",
    "# approximate Hz (ns series)\n",
    "def est_hz_ns(ts_ns: pd.Series):\n",
    "    arr = ts_ns.to_numpy()\n",
    "    if arr.size < 3: return np.nan\n",
    "    dt = np.diff(arr) / 1e9  # ns -> s\n",
    "    dt = dt[(dt > 0) & np.isfinite(dt)]\n",
    "    return float(np.median(1.0 / dt)) if dt.size else np.nan\n",
    "\n",
    "hz = recofit_df.groupby([\"subject_id\",\"session_id\"])[\"timestamp_ns\"].apply(est_hz_ns)\n",
    "print(f\"Median Hz: {np.nanmedian(hz.values):.2f} (target={SCHEMA['rate_hz']})\")\n",
    "\n",
    "# required-not-null check\n",
    "req = SCHEMA[\"expectations\"][\"required_not_null\"]\n",
    "pct = recofit_df[req].notnull().all(axis=1).mean() * 100\n",
    "print(f\"Rows meeting required-not-null: {pct:.2f}%\")\n",
    "\n",
    "print(\"Top-10 canonical labels:\")\n",
    "print(recofit_df[\"global_activity_label\"].value_counts().head(10))\n",
    "cov = (recofit_df[\"global_activity_id\"] != UNKNOWN_ID).mean()*100\n",
    "print(f\"Global mapping coverage: {cov:.1f}% (unknown={UNKNOWN_ID})\")\n",
    "print(recofit_df[\"global_activity_label\"].value_counts().head(15))\n",
    "recofit_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b20dee",
   "metadata": {},
   "source": [
    "### Step 5. Save outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d6d776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save unified RecoFit frame for later merge\n",
    "CLEANED.mkdir(parents=True, exist_ok=True)\n",
    "recofit_df.to_parquet(CLEANED / \"recofit_clean_data.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".IMU_Data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
