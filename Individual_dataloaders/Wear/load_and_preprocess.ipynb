{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a18383a3",
   "metadata": {},
   "source": [
    "## Wear Data Preprocessing notebook\n",
    "### Step 0. Setup the paths and env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfff32a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths & contracts ready.\n",
      "Schema keys: ['name', 'version', 'primary_index', 'description', 'columns', 'rate_hz', 'axis_frame', 'unit_contract', 'unknown_activity_id', 'expectations']\n",
      "RAW dir : /home/aidan/IMU_LM_Data/data/raw_data/Wear/50hz\n",
      "CLEANED : /home/aidan/IMU_LM_Data/data/cleaned_premerge\n",
      "MERGED  : /home/aidan/IMU_LM_Data/data/merged_dataset\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json, sys, re\n",
    "from typing import List, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "ROOT = Path(\"/home/aidan/IMU_LM_Data\")\n",
    "sys.path.insert(0, str(ROOT))\n",
    "from UTILS.helpers import (\n",
    "    resample_df,            # decimate FIR-based resampling (df, target_cols, factor)\n",
    "    convert_unit,           # unit conversion; here used for accel \"acc\"\n",
    "    normalize_str, keyize, _keyize\n",
    ")\n",
    "\n",
    "BASE    = ROOT / \"data\"\n",
    "RAW     = BASE / \"raw_data\" / \"Wear\" / \"50hz\"    \n",
    "CLEANED = BASE / \"cleaned_premerge\"\n",
    "MERGED  = BASE / \"merged_dataset\"\n",
    "\n",
    "SCHEMA_PATH       = ROOT / \"Unification\" / \"schemas\" / \"continuous_stream_schema.json\"\n",
    "ACTIVITY_MAP_PATH = ROOT / \"Unification\" / \"schemas\" / \"activity_mapping.json\"\n",
    "\n",
    "SCHEMA       = json.loads(SCHEMA_PATH.read_text())\n",
    "ACT_MAP_FULL = json.loads(ACTIVITY_MAP_PATH.read_text())\n",
    "\n",
    "UNKNOWN_ID = int(ACT_MAP_FULL.get(\"unknown_activity_id\", 9000))\n",
    "ID2NAME    = {int(x[\"id\"]): x[\"name\"] for x in ACT_MAP_FULL[\"label_set\"]}\n",
    "RAW2ID     = {_keyize(k): int(v) for k, v in ACT_MAP_FULL.get(\"mapping\", {}).items()}\n",
    "\n",
    "print(\"Paths & contracts ready.\")\n",
    "print(f\"Schema keys: {list(SCHEMA.keys())}\")\n",
    "print(\"RAW dir :\", RAW)\n",
    "print(\"CLEANED :\", CLEANED)\n",
    "print(\"MERGED  :\", MERGED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b57e4c8",
   "metadata": {},
   "source": [
    "### Step 1. Ingest, preporccess and map the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccef130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WEAR] Found 24 subject CSVs under /home/aidan/IMU_LM_Data/data/raw_data/Wear/50hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WEAR files:   8%|▊         | 2/24 [00:00<00:07,  2.93it/s]/tmp/ipykernel_2595459/2277237368.py:44: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f)\n",
      "WEAR files: 100%|██████████| 24/24 [00:05<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RAW SUMMARY (WEAR right wrist) ===\n",
      "Rows: 3,466,400\n",
      "Estimated Hz: ~50.00\n",
      "Top native labels (verbatim):\n",
      "activity_label_raw\n",
      "unknown                         1377362\n",
      "jogging                          125158\n",
      "jogging (sidesteps)              123374\n",
      "stretching (lunging)             122021\n",
      "lunges (complex)                 121820\n",
      "sit-ups (complex)                120555\n",
      "sit-ups                          119535\n",
      "lunges                           118323\n",
      "burpees                          116681\n",
      "stretching (triceps)             116485\n",
      "stretching (lumbar rotation)     116101\n",
      "push-ups (complex)               115867\n",
      "stretching (hamstrings)          115116\n",
      "jogging (skipping)               114037\n",
      "stretching (shoulders)           112913\n",
      "jogging (rotating arms)          109596\n",
      "push-ups                         108250\n",
      "jogging (butt-kicks)             107619\n",
      "bench-dips                       105587\n",
      "Name: count, dtype: Int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp_s</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>activity_label_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S00</td>\n",
       "      <td>ses01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.894856</td>\n",
       "      <td>0.632590</td>\n",
       "      <td>0.417429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S00</td>\n",
       "      <td>ses01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>11.536308</td>\n",
       "      <td>2.272242</td>\n",
       "      <td>-0.031430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S00</td>\n",
       "      <td>ses01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>11.017628</td>\n",
       "      <td>2.593674</td>\n",
       "      <td>-0.269356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id session_id  timestamp_s      acc_x     acc_y     acc_z  gyro_x  \\\n",
       "0        S00      ses01         0.00  10.894856  0.632590  0.417429     NaN   \n",
       "1        S00      ses01         0.02  11.536308  2.272242 -0.031430     NaN   \n",
       "2        S00      ses01         0.04  11.017628  2.593674 -0.269356     NaN   \n",
       "\n",
       "   gyro_y  gyro_z activity_label_raw  \n",
       "0     NaN     NaN            unknown  \n",
       "1     NaN     NaN            unknown  \n",
       "2     NaN     NaN            unknown  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================================\n",
    "# STEP 1 — Load WEAR (right wrist)\n",
    "# ================================\n",
    "def _collect_wear_files(raw_dir: Path) -> List[Path]:\n",
    "    files = sorted(raw_dir.glob(\"sbj_*.csv\"))\n",
    "    print(f\"[WEAR] Found {len(files)} subject CSVs under {raw_dir}\")\n",
    "    return files\n",
    "\n",
    "def _estimate_hz_from_index(n_rows: int, assumed_hz: float = 50.0) -> float:\n",
    "    # With equally spaced index-derived timestamps, the median Hz is the assumed_hz.\n",
    "    # This is a placeholder for future actual-timestamp variants.\n",
    "    return float(assumed_hz) if n_rows >= 3 else np.nan\n",
    "\n",
    "def load_wear_raw(\n",
    "    raw_dir: Path,\n",
    "    wrist: str = \"right\",               # \"right\" | \"left\"\n",
    "    downsample_to_50hz_if_needed: bool = False,  # WEAR/50hz already at 50 Hz; keep False by default\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns wrist-only (accelerometer) frame with:\n",
    "      subject_id (str), session_id (str), timestamp_s (float),\n",
    "      acc_x/y/z (m/s^2), gyro_x/y/z (NaN),\n",
    "      dataset_activity_label (str)\n",
    "    \"\"\"\n",
    "    wrist = wrist.lower()\n",
    "    assert wrist in {\"right\",\"left\"}, \"wrist must be 'right' or 'left'\"\n",
    "\n",
    "    files = _collect_wear_files(raw_dir)\n",
    "    if not files:\n",
    "        print(\"No WEAR subject CSVs found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Column templates\n",
    "    col_prefix = f\"{wrist}_arm_acc_\"\n",
    "    acc_cols = [f\"{col_prefix}x\", f\"{col_prefix}y\", f\"{col_prefix}z\"]\n",
    "\n",
    "    # Some distributions include other sensors; we ignore legs & the other wrist here\n",
    "    all_rows = []\n",
    "    dataset_name = \"wear\"\n",
    "    sampling_rate_hz = 50.0  # WEAR 50Hz split\n",
    "\n",
    "    for f in tqdm(files, desc=\"WEAR files\"):\n",
    "        try:\n",
    "            df = pd.read_csv(f)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to read {f.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Subject ID: prefer 'sbj_id' column; otherwise parse from filename\n",
    "        if \"sbj_id\" in df.columns:\n",
    "            subj_raw = str(df[\"sbj_id\"].iloc[0])\n",
    "        else:\n",
    "            m = re.match(r\"sbj_(\\d+)\\.csv$\", f.name)\n",
    "            subj_raw = m.group(1) if m else f.stem.replace(\"sbj_\",\"\")\n",
    "        subject_id = f\"S{int(subj_raw):02d}\" if str(subj_raw).isdigit() else f\"S{subj_raw}\"\n",
    "\n",
    "        # Treat each file as a single session to preserve monotonic timestamps cleanly\n",
    "        session_id = \"ses01\"\n",
    "\n",
    "        # Required columns sanity check\n",
    "        missing = [c for c in acc_cols if c not in df.columns]\n",
    "        if missing:\n",
    "            print(f\"[WARN] {f.name} missing columns: {missing} — skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Label column presence; keep even if NaN (we'll fill with 'unknown')\n",
    "        label_col = \"label\" if \"label\" in df.columns else None\n",
    "        if label_col is None:\n",
    "            # create a placeholder label column\n",
    "            df[\"label\"] = np.nan\n",
    "            label_col = \"label\"\n",
    "\n",
    "        # Build synthetic timestamp at 50 Hz from row index (0,1,2,...)/50\n",
    "        # Keep float seconds; later we convert to ns.\n",
    "        # Do NOT drop rows based on labels; retain all data.\n",
    "        n = len(df)\n",
    "        timestamps_s = np.arange(n, dtype=np.float64) / sampling_rate_hz\n",
    "\n",
    "        # Units: WEAR files store accel in g; convert to m/s^2.\n",
    "        # convert_unit(..., kind=\"acc\") is assumed to do g→m/s^2 if input is in g.\n",
    "        acc_x = convert_unit(df[acc_cols[0]].astype(np.float64).to_numpy(), kind=\"acc\")\n",
    "        acc_y = convert_unit(df[acc_cols[1]].astype(np.float64).to_numpy(), kind=\"acc\")\n",
    "        acc_z = convert_unit(df[acc_cols[2]].astype(np.float64).to_numpy(), kind=\"acc\")\n",
    "\n",
    "        # Gyro is absent → fill NaN float32 arrays\n",
    "        gyro_x = np.full(n, np.nan, dtype=np.float32)\n",
    "        gyro_y = np.full(n, np.nan, dtype=np.float32)\n",
    "        gyro_z = np.full(n, np.nan, dtype=np.float32)\n",
    "\n",
    "        # Native labels (string); we won't drop NaNs — fill to 'unknown'\n",
    "        native_lbl = df[label_col].astype(\"string\").fillna(\"unknown\")\n",
    "\n",
    "        # Assemble minimal raw frame\n",
    "        out = pd.DataFrame({\n",
    "            \"subject_id\": subject_id,\n",
    "            \"session_id\": session_id,\n",
    "            \"timestamp_s\": timestamps_s,\n",
    "\n",
    "            \"acc_x\": acc_x.astype(np.float32),\n",
    "            \"acc_y\": acc_y.astype(np.float32),\n",
    "            \"acc_z\": acc_z.astype(np.float32),\n",
    "\n",
    "            \"gyro_x\": gyro_x, \"gyro_y\": gyro_y, \"gyro_z\": gyro_z,\n",
    "            \"activity_label_raw\": native_lbl\n",
    "        })\n",
    "\n",
    "        # Optional: if provided WEAR files ever drifted from 50 Hz, resample here.\n",
    "        if downsample_to_50hz_if_needed:\n",
    "            # Guard: nothing to do since we already synthesized 50 Hz timestamps.\n",
    "            pass\n",
    "\n",
    "        out[\"subject_id\"] = out[\"subject_id\"].astype(\"string\")\n",
    "        out[\"session_id\"] = out[\"session_id\"].astype(\"string\")\n",
    "\n",
    "        all_rows.append(out)\n",
    "\n",
    "    if not all_rows:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    raw = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "    # Quick RAW SUMMARY\n",
    "    print(\"\\n=== RAW SUMMARY (WEAR right wrist) ===\")\n",
    "    print(f\"Rows: {raw.shape[0]:,}\")\n",
    "    # Estimate Hz: derived from index; report assumed 50.\n",
    "    print(f\"Estimated Hz: ~{_estimate_hz_from_index(len(raw)):0.2f}\")\n",
    "    print(\"Top native labels (verbatim):\")\n",
    "    print(raw[\"activity_label_raw\"].value_counts(dropna=False).head(20))\n",
    "\n",
    "    return raw\n",
    "\n",
    "raw_wear = load_wear_raw(RAW, wrist=\"right\", downsample_to_50hz_if_needed=False)\n",
    "raw_wear.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362aca6a",
   "metadata": {},
   "source": [
    "### Step 2. Map the data and audit the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b74f951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw label unique: 19 | Unmapped→global: 1\n",
      "Unmapped (top-10):\n",
      "raw_label   count\n",
      "  unknown 1377362\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_label</th>\n",
       "      <th>count</th>\n",
       "      <th>native_id</th>\n",
       "      <th>mapped_gid</th>\n",
       "      <th>mapped_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknown</td>\n",
       "      <td>1377362</td>\n",
       "      <td>9000</td>\n",
       "      <td>9000</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jogging</td>\n",
       "      <td>125158</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>run_jog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jogging (sidesteps)</td>\n",
       "      <td>123374</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>run_jog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stretching (lunging)</td>\n",
       "      <td>122021</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>stretching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lunges (complex)</td>\n",
       "      <td>121820</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>exercise_lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sit ups (complex)</td>\n",
       "      <td>120555</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>exercise_core</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sit ups</td>\n",
       "      <td>119535</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>exercise_core</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lunges</td>\n",
       "      <td>118323</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>exercise_lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>burpees</td>\n",
       "      <td>116681</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>exercise_plyometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stretching (triceps)</td>\n",
       "      <td>116485</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>stretching</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              raw_label    count  native_id  mapped_gid            mapped_nm\n",
       "0               unknown  1377362       9000        9000                other\n",
       "1               jogging   125158          2           3              run_jog\n",
       "2   jogging (sidesteps)   123374          5           3              run_jog\n",
       "3  stretching (lunging)   122021         15          12           stretching\n",
       "4      lunges (complex)   121820          8           7       exercise_lower\n",
       "5     sit ups (complex)   120555         12           8        exercise_core\n",
       "6               sit ups   119535         11           8        exercise_core\n",
       "7                lunges   118323          7           7       exercise_lower\n",
       "8               burpees   116681          1           9  exercise_plyometric\n",
       "9  stretching (triceps)   116485         17          12           stretching"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# STEP 2 — Quick audit: raw_label → mapped_id\n",
    "# ============================================\n",
    "if raw_wear.empty:\n",
    "    raise SystemExit(\"No WEAR rows after loading. Check RAW path/layout.\")\n",
    "\n",
    "raw_counts = (\n",
    "    raw_wear[\"activity_label_raw\"]\n",
    "        .astype(str).map(_keyize)\n",
    "        .value_counts()\n",
    "        .rename_axis(\"raw_label\")\n",
    "        .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "# Stable native ID map for this dataset (alphabetical + unknown = -1)\n",
    "# Keep a reserved -1 for unknown to be explicit.\n",
    "labels_sorted = sorted([rl for rl in raw_counts[\"raw_label\"].unique() if rl != _keyize(\"unknown\")])\n",
    "NATIVE_LBL2ID = {_keyize(\"unknown\"): UNKNOWN_ID}\n",
    "NATIVE_LBL2ID.update({lbl: i for i, lbl in enumerate(labels_sorted, start=0)})\n",
    "\n",
    "raw_counts[\"native_id\"] = raw_counts[\"raw_label\"].map(NATIVE_LBL2ID).astype(int)\n",
    "raw_counts[\"mapped_gid\"] = raw_counts[\"raw_label\"].map(RAW2ID).fillna(UNKNOWN_ID).astype(int)\n",
    "raw_counts[\"mapped_nm\"]  = raw_counts[\"mapped_gid\"].map(lambda x: ID2NAME.get(int(x), \"other\"))\n",
    "\n",
    "unmapped = raw_counts.loc[raw_counts[\"mapped_gid\"] == UNKNOWN_ID]\n",
    "print(f\"Raw label unique: {len(raw_counts)} | Unmapped→global: {len(unmapped)}\")\n",
    "print(\"Unmapped (top-10):\")\n",
    "print(unmapped.nlargest(10, \"count\")[[\"raw_label\",\"count\"]].to_string(index=False))\n",
    "raw_counts.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5232ad",
   "metadata": {},
   "source": [
    "### Step 3. Build and clean dataset in stream json fromat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3412889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIFIED rows: 3466400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp_ns</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>global_activity_id</th>\n",
       "      <th>global_activity_label</th>\n",
       "      <th>dataset_activity_id</th>\n",
       "      <th>dataset_activity_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wear</td>\n",
       "      <td>S00</td>\n",
       "      <td>ses01</td>\n",
       "      <td>0</td>\n",
       "      <td>10.894856</td>\n",
       "      <td>0.632590</td>\n",
       "      <td>0.417429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9000</td>\n",
       "      <td>other</td>\n",
       "      <td>9000</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wear</td>\n",
       "      <td>S00</td>\n",
       "      <td>ses01</td>\n",
       "      <td>20000000</td>\n",
       "      <td>11.536308</td>\n",
       "      <td>2.272242</td>\n",
       "      <td>-0.031430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9000</td>\n",
       "      <td>other</td>\n",
       "      <td>9000</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wear</td>\n",
       "      <td>S00</td>\n",
       "      <td>ses01</td>\n",
       "      <td>40000000</td>\n",
       "      <td>11.017628</td>\n",
       "      <td>2.593674</td>\n",
       "      <td>-0.269356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9000</td>\n",
       "      <td>other</td>\n",
       "      <td>9000</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset subject_id session_id  timestamp_ns      acc_x     acc_y     acc_z  \\\n",
       "0    wear        S00      ses01             0  10.894856  0.632590  0.417429   \n",
       "1    wear        S00      ses01      20000000  11.536308  2.272242 -0.031430   \n",
       "2    wear        S00      ses01      40000000  11.017628  2.593674 -0.269356   \n",
       "\n",
       "   gyro_x  gyro_y  gyro_z  global_activity_id global_activity_label  \\\n",
       "0     NaN     NaN     NaN                9000                 other   \n",
       "1     NaN     NaN     NaN                9000                 other   \n",
       "2     NaN     NaN     NaN                9000                 other   \n",
       "\n",
       "   dataset_activity_id dataset_activity_label  \n",
       "0                 9000                unknown  \n",
       "1                 9000                unknown  \n",
       "2                 9000                unknown  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================================================\n",
    "# STEP 3 — Build schema-ordered continuous_stream (v3) df\n",
    "# =========================================================\n",
    "def to_continuous_stream_wear(df_raw: pd.DataFrame, dataset_name: str = \"wear\") -> pd.DataFrame:\n",
    "    if df_raw.empty:\n",
    "        return pd.DataFrame(columns=[c[\"name\"] for c in SCHEMA[\"columns\"]])\n",
    "\n",
    "    # Native (dataset-level) ID/label: use stable map with 'unknown' → -1\n",
    "    raw_key  = df_raw[\"activity_label_raw\"].astype(str).map(_keyize)\n",
    "    native_id  = raw_key.map(NATIVE_LBL2ID).astype(np.int16)\n",
    "    native_lbl = df_raw[\"activity_label_raw\"].astype(\"string\")\n",
    "\n",
    "    # Global map via activity_mapping.json\n",
    "    gid    = raw_key.map(RAW2ID).fillna(UNKNOWN_ID).astype(np.int16)\n",
    "    glabel = gid.map(lambda x: ID2NAME.get(int(x), \"other\")).astype(\"string\")\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"dataset\":                dataset_name,\n",
    "        \"subject_id\":             df_raw[\"subject_id\"].astype(\"string\"),\n",
    "        \"session_id\":             df_raw[\"session_id\"].astype(\"string\"),\n",
    "        \"timestamp_ns\":           (df_raw[\"timestamp_s\"].astype(np.float64) * 1e9).round().astype(\"int64\"),\n",
    "\n",
    "        \"acc_x\": df_raw[\"acc_x\"].astype(\"float32\"),\n",
    "        \"acc_y\": df_raw[\"acc_y\"].astype(\"float32\"),\n",
    "        \"acc_z\": df_raw[\"acc_z\"].astype(\"float32\"),\n",
    "        \"gyro_x\": df_raw[\"gyro_x\"].astype(\"float32\"),\n",
    "        \"gyro_y\": df_raw[\"gyro_y\"].astype(\"float32\"),\n",
    "        \"gyro_z\": df_raw[\"gyro_z\"].astype(\"float32\"),\n",
    "\n",
    "        \"global_activity_id\":     gid,\n",
    "        \"global_activity_label\":  glabel,\n",
    "\n",
    "        \"dataset_activity_id\":    native_id,\n",
    "        \"dataset_activity_label\": native_lbl,\n",
    "    })\n",
    "\n",
    "    # Enforce schema column order\n",
    "    order = [c[\"name\"] for c in SCHEMA[\"columns\"]]\n",
    "    return out[order]\n",
    "\n",
    "wear_df = to_continuous_stream_wear(raw_wear, dataset_name=\"wear\")\n",
    "print(\"UNIFIED rows:\", len(wear_df))\n",
    "wear_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bef200c",
   "metadata": {},
   "source": [
    "### Step 4. Audit check the unified frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba60e5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects: 24 | Sessions: 1\n",
      "Monotonic violations (groups): 0\n",
      "Median Hz: 50.00 (target=50)\n",
      "Rows meeting required-not-null: 100.00%\n",
      "Global mapping coverage: 60.3% (unknown=9000)\n",
      "\n",
      "Top-15 canonical labels:\n",
      "global_activity_label\n",
      "other                  1377362\n",
      "stretching              582636\n",
      "run_jog                 579784\n",
      "exercise_upper          329704\n",
      "exercise_lower          240143\n",
      "exercise_core           240090\n",
      "exercise_plyometric     116681\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# STEP 4 — Contract checks & quick QA\n",
    "# ==========================================\n",
    "print(\"Subjects:\", wear_df[\"subject_id\"].nunique(),\n",
    "      \"| Sessions:\", wear_df[\"session_id\"].nunique())\n",
    "\n",
    "# Monotonic timestamp per (subject, session)\n",
    "viol = 0\n",
    "for (_sid, _sess), g in wear_df.groupby([\"subject_id\",\"session_id\"], sort=False):\n",
    "    ts = g[\"timestamp_ns\"].to_numpy()\n",
    "    if ts.size and not np.all(np.diff(ts) >= 0):\n",
    "        viol += 1\n",
    "print(\"Monotonic violations (groups):\", viol)\n",
    "\n",
    "# Approx Hz from ns timestamps\n",
    "def est_hz_ns(ts_ns: pd.Series):\n",
    "    arr = ts_ns.to_numpy()\n",
    "    if arr.size < 3: return np.nan\n",
    "    dt = np.diff(arr) / 1e9  # ns → s\n",
    "    dt = dt[(dt > 0) & np.isfinite(dt)]\n",
    "    return float(np.median(1.0 / dt)) if dt.size else np.nan\n",
    "\n",
    "hz = wear_df.groupby([\"subject_id\",\"session_id\"])[\"timestamp_ns\"].apply(est_hz_ns)\n",
    "print(f\"Median Hz: {np.nanmedian(hz.values):.2f} (target={SCHEMA['rate_hz']})\")\n",
    "\n",
    "# Required-not-null coverage\n",
    "req = SCHEMA[\"expectations\"][\"required_not_null\"]\n",
    "pct = wear_df[req].notnull().all(axis=1).mean() * 100\n",
    "print(f\"Rows meeting required-not-null: {pct:.2f}%\")\n",
    "\n",
    "# Global mapping coverage\n",
    "cov = (wear_df[\"global_activity_id\"] != UNKNOWN_ID).mean() * 100\n",
    "print(f\"Global mapping coverage: {cov:.1f}% (unknown={UNKNOWN_ID})\")\n",
    "\n",
    "# Quick canonical label distribution\n",
    "print(\"\\nTop-15 canonical labels:\")\n",
    "print(wear_df[\"global_activity_label\"].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f95e688",
   "metadata": {},
   "source": [
    "### Step 5. Save outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f714866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/aidan/IMU_LM_Data/data/cleaned_premerge/wear_clean_data.parquet\n"
     ]
    }
   ],
   "source": [
    "# Persist\n",
    "CLEANED.mkdir(parents=True, exist_ok=True)\n",
    "out_path = CLEANED / \"wear_clean_data.parquet\"\n",
    "wear_df.to_parquet(out_path, index=False)\n",
    "print(\"Saved:\", out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".IMU_Data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
